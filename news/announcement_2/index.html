<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <p>In recent years approximately $30 billion has been invested in the development of Autonomous Vehicles (AVs). The increasing adoption of AVs demands precise Lane and Obstacle Detection (LOD) to ensure safe and reliable transportation. This paper aims to propose a monocular camera-based LOD method for Autonomous Driving (AD). We employed YOLO, for real-time object detection while Convolutional Neural Networks (CNNs) extract lane boundaries for accurate road mapping. Our approach utilizes Intersection over Union (IoU) for effective object tracking, allowing us to associate detected vehicles across frames and enhance Lane Detection (LD) accuracy. Dash cameraâ€™s data provides a top view of the scene, while adaptive thresholding technique with sliding windows ensures reliable detection. YOLO11s improves real-time detection, and achieved a mAP50 of 0.818 over YOLOv5s (0.691) and YOLOv8s (0.687), demonstrating the effectiveness of ObstaLaneYOLO.</p> <h4 id="key-words">Key Words</h4> <ul> <li>Lane Detection</li> <li> Obstacle Detection</li> <li>Autonomous Driving</li> <li>Camera-Based Perception</li> <li>YOLO</li> </ul> <hr> </body></html>